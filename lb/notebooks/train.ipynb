{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d2b61-9e45-420d-af82-6717f853736d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T04:33:26.804132Z",
     "iopub.status.busy": "2024-05-27T04:33:26.803714Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-26 21:33:28,468] torch.distributed.run: [WARNING] \n",
      "[2024-05-26 21:33:28,468] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-05-26 21:33:28,468] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-05-26 21:33:28,468] torch.distributed.run: [WARNING] *****************************************\n",
      "2024-05-26 21:33:34,822 - train - INFO - running /lfs/ampere2/0/ranjanr/cs336-a4/cs336-basics/cs336_basics/scripts/train.py --train-path ../scratch/paloma_c4_100_domains_val_tokenized.bin --dev-path ../scratch/paloma_c4_100_domains_val_tokenized.bin --output-dir out/train_on_val --vocab-size 50257 --context-length 512 --d-model 768 --num-layers 12 --num-heads 12 --d-ff 3072 --attn-pdrop 0.1 --residual-pdrop 0.1 --batch-size 32 --train-steps 200000 --eval-iters 1000 --eval-interval 2000 --learning-rate 1e-3 --lr-scheduler cosine --weight-decay 0.1 --warmup-ratio 0.01 --grad-clip 1.0 --dtype bfloat16 --wandb-project cs336-a4 --compile\n",
      "2024-05-26 21:33:35,625 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,633 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,642 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,653 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,654 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,662 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:35,668 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:37,144 - model - INFO - number of non-embedding parameters: 123.55M\n",
      "2024-05-26 21:33:37,680 - train - INFO - Total number of tokens per training step: 131072\n",
      "2024-05-26 21:33:37,680 - train - INFO - Saving model config to out/train_on_val/model_config.json\n",
      "2024-05-26 21:33:37,680 - train - INFO - Using dtype: torch.bfloat16\n",
      "  0%|                        | 1/200000 [01:01<3429:56:44, 61.74s/it]2024-05-26 21:34:51,821 - train - INFO - Train step 0, Loss: 453.579833984375\n",
      "  0%|                        | 2/200000 [01:01<1417:31:25, 25.52s/it]2024-05-26 21:34:51,980 - train - INFO - Train step 1, Loss: 452.1600341796875\n",
      "  0%|                         | 3/200000 [01:02<773:55:04, 13.93s/it]2024-05-26 21:34:52,123 - train - INFO - Train step 2, Loss: 453.174560546875\n",
      "  0%|                         | 4/200000 [01:02<471:31:58,  8.49s/it]2024-05-26 21:34:52,268 - train - INFO - Train step 3, Loss: 453.287841796875\n",
      "  0%|                         | 5/200000 [01:02<304:20:16,  5.48s/it]2024-05-26 21:34:52,412 - train - INFO - Train step 4, Loss: 447.5670166015625\n",
      "  0%|                         | 6/200000 [01:02<203:34:40,  3.66s/it]2024-05-26 21:34:52,555 - train - INFO - Train step 5, Loss: 451.21435546875\n",
      "  0%|                         | 7/200000 [01:02<139:39:02,  2.51s/it]2024-05-26 21:34:52,699 - train - INFO - Train step 6, Loss: 450.5284423828125\n",
      "  0%|                          | 8/200000 [01:02<97:46:18,  1.76s/it]2024-05-26 21:34:52,845 - train - INFO - Train step 7, Loss: 447.0712890625\n",
      "  0%|                          | 9/200000 [01:02<69:42:32,  1.25s/it]2024-05-26 21:34:52,989 - train - INFO - Train step 8, Loss: 444.46484375\n",
      "  0%|                         | 10/200000 [01:03<50:48:35,  1.09it/s]2024-05-26 21:34:53,142 - train - INFO - Train step 9, Loss: 441.9722900390625\n",
      "  0%|                         | 10/200000 [01:03<50:46:51,  1.09it/s]2024-05-26 21:34:53,286 - train - INFO - Train step 10, Loss: 433.069580078125\n",
      "  0%|                         | 12/200000 [01:03<28:42:12,  1.94it/s]2024-05-26 21:34:53,432 - train - INFO - Train step 11, Loss: 434.9625244140625\n",
      "  0%|                         | 13/200000 [01:03<22:26:20,  2.48it/s]2024-05-26 21:34:53,577 - train - INFO - Train step 12, Loss: 430.165771484375\n",
      "  0%|                         | 14/200000 [01:03<18:07:04,  3.07it/s]2024-05-26 21:34:53,723 - train - INFO - Train step 13, Loss: 424.640380859375\n",
      "  0%|                         | 15/200000 [01:03<15:03:26,  3.69it/s]2024-05-26 21:34:53,867 - train - INFO - Train step 14, Loss: 418.289306640625\n",
      "  0%|                         | 16/200000 [01:03<12:57:38,  4.29it/s]2024-05-26 21:34:54,012 - train - INFO - Train step 15, Loss: 409.6075439453125\n",
      "  0%|                         | 17/200000 [01:04<11:27:40,  4.85it/s]2024-05-26 21:34:54,156 - train - INFO - Train step 16, Loss: 402.6455078125\n",
      "  0%|                         | 17/200000 [01:04<11:27:47,  4.85it/s]2024-05-26 21:34:54,302 - train - INFO - Train step 17, Loss: 392.00164794921875\n",
      "  0%|                          | 19/200000 [01:04<9:43:59,  5.71it/s]2024-05-26 21:34:54,447 - train - INFO - Train step 18, Loss: 380.634521484375\n",
      "  0%|                          | 19/200000 [01:04<9:44:47,  5.70it/s]2024-05-26 21:34:54,599 - train - INFO - Train step 19, Loss: 363.74737548828125\n",
      "  0%|                          | 20/200000 [01:04<9:21:07,  5.94it/s]2024-05-26 21:34:54,747 - train - INFO - Train step 20, Loss: 354.31182861328125\n",
      "  0%|                          | 22/200000 [01:04<8:42:59,  6.37it/s]2024-05-26 21:34:54,892 - train - INFO - Train step 21, Loss: 339.683349609375\n",
      "  0%|                          | 23/200000 [01:04<8:30:44,  6.53it/s]2024-05-26 21:34:55,036 - train - INFO - Train step 22, Loss: 324.1715087890625\n",
      "  0%|                          | 24/200000 [01:05<8:22:01,  6.64it/s]2024-05-26 21:34:55,181 - train - INFO - Train step 23, Loss: 309.85113525390625\n",
      "  0%|                          | 25/200000 [01:05<8:18:06,  6.69it/s]2024-05-26 21:34:55,328 - train - INFO - Train step 24, Loss: 293.59326171875\n",
      "  0%|                          | 26/200000 [01:05<8:13:39,  6.75it/s]2024-05-26 21:34:55,472 - train - INFO - Train step 25, Loss: 276.5616455078125\n",
      "  0%|                          | 27/200000 [01:05<8:09:28,  6.81it/s]2024-05-26 21:34:55,616 - train - INFO - Train step 26, Loss: 260.3045349121094\n",
      "  0%|                          | 28/200000 [01:05<8:06:52,  6.85it/s]2024-05-26 21:34:55,761 - train - INFO - Train step 27, Loss: 246.46487426757812\n",
      "  0%|                          | 29/200000 [01:05<8:05:16,  6.87it/s]2024-05-26 21:34:55,905 - train - INFO - Train step 28, Loss: 230.63522338867188\n",
      "  0%|                          | 30/200000 [01:05<8:04:01,  6.89it/s]2024-05-26 21:34:56,050 - train - INFO - Train step 29, Loss: 216.24951171875\n",
      "  0%|                          | 30/200000 [01:05<8:04:01,  6.89it/s]2024-05-26 21:34:56,193 - train - INFO - Train step 30, Loss: 202.2005615234375\n",
      "  0%|                          | 32/200000 [01:06<8:00:56,  6.93it/s]2024-05-26 21:34:56,336 - train - INFO - Train step 31, Loss: 188.88360595703125\n",
      "  0%|                          | 33/200000 [01:06<7:59:55,  6.94it/s]2024-05-26 21:34:56,480 - train - INFO - Train step 32, Loss: 177.59400939941406\n",
      "  0%|                          | 34/200000 [01:06<7:59:31,  6.95it/s]2024-05-26 21:34:56,623 - train - INFO - Train step 33, Loss: 166.00546264648438\n",
      "  0%|                          | 35/200000 [01:06<7:59:21,  6.95it/s]2024-05-26 21:34:56,767 - train - INFO - Train step 34, Loss: 156.16554260253906\n",
      "  0%|                          | 36/200000 [01:06<7:59:16,  6.95it/s]2024-05-26 21:34:56,911 - train - INFO - Train step 35, Loss: 146.79165649414062\n",
      "  0%|                          | 37/200000 [01:06<7:59:26,  6.95it/s]2024-05-26 21:34:57,055 - train - INFO - Train step 36, Loss: 138.68795776367188\n",
      "  0%|                          | 38/200000 [01:07<7:59:24,  6.95it/s]2024-05-26 21:34:57,199 - train - INFO - Train step 37, Loss: 128.41908264160156\n",
      "  0%|                          | 39/200000 [01:07<7:59:13,  6.95it/s]2024-05-26 21:34:57,342 - train - INFO - Train step 38, Loss: 124.86321258544922\n",
      "  0%|                          | 40/200000 [01:07<7:59:08,  6.96it/s]2024-05-26 21:34:57,486 - train - INFO - Train step 39, Loss: 118.99877166748047\n",
      "  0%|                          | 41/200000 [01:07<7:59:01,  6.96it/s]2024-05-26 21:34:57,630 - train - INFO - Train step 40, Loss: 113.48310089111328\n",
      "  0%|                          | 42/200000 [01:07<7:58:45,  6.96it/s]2024-05-26 21:34:57,773 - train - INFO - Train step 41, Loss: 108.95846557617188\n",
      "  0%|                          | 43/200000 [01:07<7:59:16,  6.95it/s]2024-05-26 21:34:57,917 - train - INFO - Train step 42, Loss: 104.9611587524414\n",
      "  0%|                          | 44/200000 [01:07<7:59:26,  6.95it/s]2024-05-26 21:34:58,061 - train - INFO - Train step 43, Loss: 100.89799499511719\n",
      "  0%|                          | 45/200000 [01:08<7:58:45,  6.96it/s]2024-05-26 21:34:58,205 - train - INFO - Train step 44, Loss: 99.01605224609375\n",
      "  0%|                          | 46/200000 [01:08<8:02:14,  6.91it/s]2024-05-26 21:34:58,352 - train - INFO - Train step 45, Loss: 96.06230163574219\n",
      "  0%|                          | 47/200000 [01:08<8:01:55,  6.92it/s]2024-05-26 21:34:58,497 - train - INFO - Train step 46, Loss: 93.56647491455078\n",
      "  0%|                          | 48/200000 [01:08<8:01:21,  6.92it/s]2024-05-26 21:34:58,640 - train - INFO - Train step 47, Loss: 90.39540100097656\n",
      "  0%|                          | 49/200000 [01:08<8:00:44,  6.93it/s]2024-05-26 21:34:58,784 - train - INFO - Train step 48, Loss: 89.1028060913086\n",
      "  0%|                          | 49/200000 [01:08<8:00:33,  6.93it/s]2024-05-26 21:34:58,928 - train - INFO - Train step 49, Loss: 86.65637969970703\n",
      "  0%|                          | 51/200000 [01:08<8:00:32,  6.93it/s]2024-05-26 21:34:59,072 - train - INFO - Train step 50, Loss: 84.630859375\n",
      "  0%|                          | 52/200000 [01:09<7:59:49,  6.95it/s]2024-05-26 21:34:59,216 - train - INFO - Train step 51, Loss: 81.60861206054688\n",
      "  0%|                          | 52/200000 [01:09<8:00:01,  6.94it/s]2024-05-26 21:34:59,360 - train - INFO - Train step 52, Loss: 80.9013671875\n",
      "  0%|                          | 54/200000 [01:09<8:00:15,  6.94it/s]2024-05-26 21:34:59,505 - train - INFO - Train step 53, Loss: 79.25059509277344\n",
      "  0%|                          | 55/200000 [01:09<8:00:02,  6.94it/s]2024-05-26 21:34:59,648 - train - INFO - Train step 54, Loss: 77.51378631591797\n",
      "  0%|                          | 56/200000 [01:09<7:59:41,  6.95it/s]2024-05-26 21:34:59,792 - train - INFO - Train step 55, Loss: 76.04859924316406\n",
      "  0%|                          | 57/200000 [01:09<7:59:36,  6.95it/s]2024-05-26 21:34:59,936 - train - INFO - Train step 56, Loss: 74.92716217041016\n",
      "  0%|                          | 58/200000 [01:09<7:59:57,  6.94it/s]2024-05-26 21:35:00,080 - train - INFO - Train step 57, Loss: 74.56556701660156\n",
      "  0%|                          | 59/200000 [01:10<7:59:56,  6.94it/s]2024-05-26 21:35:00,224 - train - INFO - Train step 58, Loss: 72.96406555175781\n",
      "  0%|                          | 60/200000 [01:10<7:59:45,  6.95it/s]2024-05-26 21:35:00,368 - train - INFO - Train step 59, Loss: 70.73245239257812\n",
      "  0%|                          | 60/200000 [01:10<7:59:44,  6.95it/s]2024-05-26 21:35:00,512 - train - INFO - Train step 60, Loss: 70.17282104492188\n",
      "  0%|                          | 62/200000 [01:10<7:59:44,  6.95it/s]2024-05-26 21:35:00,656 - train - INFO - Train step 61, Loss: 69.48873901367188\n",
      "  0%|                          | 62/200000 [01:10<7:59:50,  6.94it/s]2024-05-26 21:35:00,801 - train - INFO - Train step 62, Loss: 68.3492431640625\n",
      "  0%|                          | 64/200000 [01:10<8:00:14,  6.94it/s]2024-05-26 21:35:00,945 - train - INFO - Train step 63, Loss: 67.71418762207031\n",
      "  0%|                          | 65/200000 [01:11<8:00:14,  6.94it/s]2024-05-26 21:35:01,089 - train - INFO - Train step 64, Loss: 66.05348205566406\n",
      "  0%|                          | 65/200000 [01:11<8:00:12,  6.94it/s]2024-05-26 21:35:01,232 - train - INFO - Train step 65, Loss: 64.45220947265625\n",
      "  0%|                          | 67/200000 [01:11<7:59:45,  6.95it/s]2024-05-26 21:35:01,376 - train - INFO - Train step 66, Loss: 64.28758239746094\n",
      "  0%|                          | 68/200000 [01:11<8:00:19,  6.94it/s]2024-05-26 21:35:01,521 - train - INFO - Train step 67, Loss: 62.843502044677734\n",
      "  0%|                          | 69/200000 [01:11<7:59:53,  6.94it/s]2024-05-26 21:35:01,665 - train - INFO - Train step 68, Loss: 61.685638427734375\n",
      "  0%|                          | 70/200000 [01:11<7:59:38,  6.95it/s]2024-05-26 21:35:01,808 - train - INFO - Train step 69, Loss: 61.60026550292969\n",
      "  0%|                          | 71/200000 [01:11<7:59:47,  6.95it/s]2024-05-26 21:35:01,952 - train - INFO - Train step 70, Loss: 61.00101852416992\n",
      "  0%|                          | 72/200000 [01:12<7:59:57,  6.94it/s]2024-05-26 21:35:02,097 - train - INFO - Train step 71, Loss: 60.29253387451172\n",
      "  0%|                          | 73/200000 [01:12<7:59:44,  6.95it/s]2024-05-26 21:35:02,240 - train - INFO - Train step 72, Loss: 58.490440368652344\n",
      "  0%|                          | 73/200000 [01:12<7:59:42,  6.95it/s]2024-05-26 21:35:02,384 - train - INFO - Train step 73, Loss: 58.42864227294922\n",
      "  0%|                          | 75/200000 [01:12<7:59:56,  6.94it/s]2024-05-26 21:35:02,529 - train - INFO - Train step 74, Loss: 57.869956970214844\n",
      "  0%|                          | 76/200000 [01:12<7:59:38,  6.95it/s]2024-05-26 21:35:02,672 - train - INFO - Train step 75, Loss: 56.914398193359375\n",
      "  0%|                          | 76/200000 [01:12<7:59:39,  6.95it/s]2024-05-26 21:35:02,817 - train - INFO - Train step 76, Loss: 55.806060791015625\n",
      "  0%|                          | 78/200000 [01:12<8:00:27,  6.94it/s]2024-05-26 21:35:02,961 - train - INFO - Train step 77, Loss: 55.959964752197266\n",
      "  0%|                          | 79/200000 [01:13<8:00:24,  6.94it/s]2024-05-26 21:35:03,105 - train - INFO - Train step 78, Loss: 54.7943115234375\n",
      "  0%|                          | 80/200000 [01:13<8:00:01,  6.94it/s]2024-05-26 21:35:03,249 - train - INFO - Train step 79, Loss: 54.98695373535156\n",
      "  0%|                          | 81/200000 [01:13<7:59:32,  6.95it/s]2024-05-26 21:35:03,393 - train - INFO - Train step 80, Loss: 53.369781494140625\n",
      "  0%|                          | 82/200000 [01:13<8:00:01,  6.94it/s]2024-05-26 21:35:03,537 - train - INFO - Train step 81, Loss: 54.39939498901367\n",
      "  0%|                          | 82/200000 [01:13<8:00:11,  6.94it/s]2024-05-26 21:35:03,681 - train - INFO - Train step 82, Loss: 54.154762268066406\n",
      "  0%|                          | 83/200000 [01:13<7:59:59,  6.94it/s]2024-05-26 21:35:03,825 - train - INFO - Train step 83, Loss: 52.443668365478516\n",
      "  0%|                          | 85/200000 [01:13<8:00:01,  6.94it/s]2024-05-26 21:35:03,969 - train - INFO - Train step 84, Loss: 52.51663589477539\n",
      "  0%|                          | 86/200000 [01:14<8:00:04,  6.94it/s]2024-05-26 21:35:04,113 - train - INFO - Train step 85, Loss: 52.1461067199707\n",
      "  0%|                          | 87/200000 [01:14<8:01:04,  6.93it/s]2024-05-26 21:35:04,259 - train - INFO - Train step 86, Loss: 51.06472396850586\n",
      "  0%|                          | 87/200000 [01:14<8:01:09,  6.92it/s]2024-05-26 21:35:04,403 - train - INFO - Train step 87, Loss: 50.948577880859375\n",
      "  0%|                          | 89/200000 [01:14<8:00:31,  6.93it/s]2024-05-26 21:35:04,547 - train - INFO - Train step 88, Loss: 51.06789779663086\n",
      "  0%|                          | 89/200000 [01:14<8:00:31,  6.93it/s]2024-05-26 21:35:04,691 - train - INFO - Train step 89, Loss: 50.15325927734375\n",
      "  0%|                          | 91/200000 [01:14<8:00:47,  6.93it/s]2024-05-26 21:35:04,835 - train - INFO - Train step 90, Loss: 49.79228210449219\n",
      "  0%|                          | 92/200000 [01:14<8:02:49,  6.90it/s]2024-05-26 21:35:04,982 - train - INFO - Train step 91, Loss: 49.19319152832031\n",
      "  0%|                          | 92/200000 [01:14<8:03:03,  6.90it/s]2024-05-26 21:35:05,126 - train - INFO - Train step 92, Loss: 48.88428497314453\n",
      "  0%|                          | 94/200000 [01:15<8:01:32,  6.92it/s]2024-05-26 21:35:05,270 - train - INFO - Train step 93, Loss: 48.16938781738281\n",
      "  0%|                          | 95/200000 [01:15<8:01:40,  6.92it/s]2024-05-26 21:35:05,415 - train - INFO - Train step 94, Loss: 47.82155227661133\n",
      "  0%|                          | 96/200000 [01:15<8:02:11,  6.91it/s]2024-05-26 21:35:05,560 - train - INFO - Train step 95, Loss: 47.93264389038086\n",
      "  0%|                          | 97/200000 [01:15<8:01:56,  6.91it/s]2024-05-26 21:35:05,704 - train - INFO - Train step 96, Loss: 46.97312927246094\n",
      "  0%|                          | 97/200000 [01:15<8:01:57,  6.91it/s]2024-05-26 21:35:05,848 - train - INFO - Train step 97, Loss: 48.0385627746582\n",
      "  0%|                          | 99/200000 [01:15<8:01:11,  6.92it/s]2024-05-26 21:35:05,993 - train - INFO - Train step 98, Loss: 48.05508804321289\n",
      "  0%|                         | 100/200000 [01:16<8:00:14,  6.94it/s]2024-05-26 21:35:06,136 - train - INFO - Train step 99, Loss: 46.98941421508789\n",
      "  0%|                         | 100/200000 [01:16<8:00:23,  6.94it/s]2024-05-26 21:35:06,280 - train - INFO - Train step 100, Loss: 46.630523681640625\n",
      "  0%|                         | 102/200000 [01:16<7:59:59,  6.94it/s]2024-05-26 21:35:06,424 - train - INFO - Train step 101, Loss: 45.857322692871094\n",
      "  0%|                         | 103/200000 [01:16<8:00:10,  6.94it/s]2024-05-26 21:35:06,569 - train - INFO - Train step 102, Loss: 46.992374420166016\n",
      "  0%|                         | 104/200000 [01:16<8:00:34,  6.93it/s]2024-05-26 21:35:06,713 - train - INFO - Train step 103, Loss: 46.31025695800781\n",
      "  0%|                         | 105/200000 [01:16<8:00:56,  6.93it/s]2024-05-26 21:35:06,858 - train - INFO - Train step 104, Loss: 44.597103118896484\n",
      "  0%|                         | 106/200000 [01:16<8:00:47,  6.93it/s]2024-05-26 21:35:07,002 - train - INFO - Train step 105, Loss: 46.553009033203125\n",
      "  0%|                         | 106/200000 [01:16<8:00:46,  6.93it/s]2024-05-26 21:35:07,146 - train - INFO - Train step 106, Loss: 45.53571701049805\n",
      "  0%|                         | 107/200000 [01:17<8:00:21,  6.94it/s]2024-05-26 21:35:07,290 - train - INFO - Train step 107, Loss: 44.17377853393555\n",
      "  0%|                         | 108/200000 [01:17<8:00:30,  6.93it/s]2024-05-26 21:35:07,434 - train - INFO - Train step 108, Loss: 43.83730697631836\n",
      "  0%|                         | 110/200000 [01:17<8:00:18,  6.94it/s]2024-05-26 21:35:07,578 - train - INFO - Train step 109, Loss: 43.682594299316406\n",
      "  0%|                         | 111/200000 [01:17<8:00:21,  6.94it/s]2024-05-26 21:35:07,722 - train - INFO - Train step 110, Loss: 44.70873260498047\n",
      "  0%|                         | 112/200000 [01:17<8:00:12,  6.94it/s]2024-05-26 21:35:07,867 - train - INFO - Train step 111, Loss: 44.00798797607422\n",
      "  0%|                         | 113/200000 [01:17<8:01:04,  6.93it/s]2024-05-26 21:35:08,012 - train - INFO - Train step 112, Loss: 43.52955627441406\n",
      "  0%|                         | 114/200000 [01:18<8:01:08,  6.92it/s]2024-05-26 21:35:08,156 - train - INFO - Train step 113, Loss: 43.30796813964844\n",
      "  0%|                         | 115/200000 [01:18<8:00:41,  6.93it/s]2024-05-26 21:35:08,300 - train - INFO - Train step 114, Loss: 43.15346145629883\n",
      "  0%|                         | 115/200000 [01:18<8:00:45,  6.93it/s]2024-05-26 21:35:08,444 - train - INFO - Train step 115, Loss: 42.91919708251953\n",
      "  0%|                         | 116/200000 [01:18<8:00:22,  6.93it/s]2024-05-26 21:35:08,588 - train - INFO - Train step 116, Loss: 43.02593231201172\n",
      "  0%|                         | 118/200000 [01:18<8:00:30,  6.93it/s]2024-05-26 21:35:08,733 - train - INFO - Train step 117, Loss: 43.40626525878906\n",
      "  0%|                         | 119/200000 [01:18<8:01:00,  6.93it/s]2024-05-26 21:35:08,877 - train - INFO - Train step 118, Loss: 41.88124084472656\n",
      "  0%|                         | 120/200000 [01:18<8:01:22,  6.92it/s]2024-05-26 21:35:09,022 - train - INFO - Train step 119, Loss: 42.42900848388672\n",
      "  0%|                         | 121/200000 [01:19<8:00:36,  6.93it/s]2024-05-26 21:35:09,166 - train - INFO - Train step 120, Loss: 43.02609634399414\n",
      "  0%|                         | 122/200000 [01:19<8:00:09,  6.94it/s]2024-05-26 21:35:09,310 - train - INFO - Train step 121, Loss: 42.495784759521484\n",
      "  0%|                         | 123/200000 [01:19<8:00:21,  6.93it/s]2024-05-26 21:35:09,454 - train - INFO - Train step 122, Loss: 42.43504333496094\n",
      "  0%|                         | 123/200000 [01:19<8:00:20,  6.94it/s]2024-05-26 21:35:09,598 - train - INFO - Train step 123, Loss: 42.249385833740234\n",
      "  0%|                         | 125/200000 [01:19<8:00:36,  6.93it/s]2024-05-26 21:35:09,743 - train - INFO - Train step 124, Loss: 41.24846267700195\n",
      "  0%|                         | 125/200000 [01:19<8:00:39,  6.93it/s]2024-05-26 21:35:09,887 - train - INFO - Train step 125, Loss: 41.814361572265625\n",
      "  0%|                         | 127/200000 [01:19<8:01:11,  6.92it/s]2024-05-26 21:35:10,032 - train - INFO - Train step 126, Loss: 41.28376388549805\n",
      "  0%|                         | 128/200000 [01:20<8:01:16,  6.92it/s]2024-05-26 21:35:10,177 - train - INFO - Train step 127, Loss: 42.31135940551758\n",
      "  0%|                         | 128/200000 [01:20<8:01:22,  6.92it/s]2024-05-26 21:35:10,321 - train - INFO - Train step 128, Loss: 41.4570426940918\n",
      "  0%|                         | 130/200000 [01:20<8:01:12,  6.92it/s]2024-05-26 21:35:10,465 - train - INFO - Train step 129, Loss: 41.6407470703125\n",
      "  0%|                         | 130/200000 [01:20<8:01:13,  6.92it/s]2024-05-26 21:35:10,609 - train - INFO - Train step 130, Loss: 40.477516174316406\n",
      "  0%|                         | 131/200000 [01:20<8:00:49,  6.93it/s]2024-05-26 21:35:10,754 - train - INFO - Train step 131, Loss: 41.06243896484375\n",
      "  0%|                         | 133/200000 [01:20<8:00:28,  6.93it/s]2024-05-26 21:35:10,898 - train - INFO - Train step 132, Loss: 41.0353889465332\n",
      "  0%|                         | 133/200000 [01:20<8:00:44,  6.93it/s]2024-05-26 21:35:11,045 - train - INFO - Train step 133, Loss: 40.2496223449707\n",
      "  0%|                         | 135/200000 [01:21<8:02:53,  6.90it/s]2024-05-26 21:35:11,190 - train - INFO - Train step 134, Loss: 40.627071380615234\n",
      "  0%|                         | 136/200000 [01:21<8:01:44,  6.91it/s]2024-05-26 21:35:11,333 - train - INFO - Train step 135, Loss: 40.92350769042969\n",
      "  0%|                         | 137/200000 [01:21<8:01:41,  6.92it/s]2024-05-26 21:35:11,478 - train - INFO - Train step 136, Loss: 40.923858642578125\n",
      "  0%|                         | 137/200000 [01:21<8:01:41,  6.92it/s]2024-05-26 21:35:11,622 - train - INFO - Train step 137, Loss: 41.43285369873047\n",
      "  0%|                         | 138/200000 [01:21<8:01:15,  6.92it/s]2024-05-26 21:35:11,767 - train - INFO - Train step 138, Loss: 39.92853927612305\n",
      "  0%|                         | 139/200000 [01:21<8:01:17,  6.92it/s]2024-05-26 21:35:11,911 - train - INFO - Train step 139, Loss: 40.84595489501953\n",
      "  0%|                         | 141/200000 [01:21<8:01:05,  6.92it/s]2024-05-26 21:35:12,056 - train - INFO - Train step 140, Loss: 41.23122787475586\n",
      "  0%|                         | 142/200000 [01:22<8:01:25,  6.92it/s]2024-05-26 21:35:12,200 - train - INFO - Train step 141, Loss: 40.12895965576172\n",
      "  0%|                         | 143/200000 [01:22<8:00:52,  6.93it/s]2024-05-26 21:35:12,344 - train - INFO - Train step 142, Loss: 40.04059982299805\n",
      "  0%|                         | 143/200000 [01:22<8:00:53,  6.93it/s]2024-05-26 21:35:12,488 - train - INFO - Train step 143, Loss: 39.49578857421875\n",
      "  0%|                         | 145/200000 [01:22<8:00:41,  6.93it/s]2024-05-26 21:35:12,633 - train - INFO - Train step 144, Loss: 39.5107421875\n",
      "  0%|                         | 146/200000 [01:22<8:00:33,  6.93it/s]2024-05-26 21:35:12,777 - train - INFO - Train step 145, Loss: 39.226539611816406\n",
      "  0%|                         | 146/200000 [01:22<8:00:39,  6.93it/s]2024-05-26 21:35:12,921 - train - INFO - Train step 146, Loss: 39.7321662902832\n",
      "  0%|                         | 148/200000 [01:22<8:00:46,  6.93it/s]2024-05-26 21:35:13,066 - train - INFO - Train step 147, Loss: 38.83568572998047\n",
      "  0%|                         | 149/200000 [01:23<8:01:12,  6.92it/s]2024-05-26 21:35:13,210 - train - INFO - Train step 148, Loss: 38.439998626708984\n",
      "  0%|                         | 150/200000 [01:23<8:01:17,  6.92it/s]2024-05-26 21:35:13,355 - train - INFO - Train step 149, Loss: 38.714717864990234\n",
      "  0%|                         | 151/200000 [01:23<8:01:31,  6.92it/s]2024-05-26 21:35:13,500 - train - INFO - Train step 150, Loss: 39.17012023925781\n",
      "  0%|                         | 152/200000 [01:23<8:01:10,  6.92it/s]2024-05-26 21:35:13,644 - train - INFO - Train step 151, Loss: 38.585628509521484\n",
      "  0%|                         | 153/200000 [01:23<8:01:23,  6.92it/s]2024-05-26 21:35:13,789 - train - INFO - Train step 152, Loss: 38.66613006591797\n",
      "  0%|                         | 154/200000 [01:23<8:01:08,  6.92it/s]2024-05-26 21:35:13,933 - train - INFO - Train step 153, Loss: 38.5814094543457\n",
      "  0%|                         | 155/200000 [01:23<8:00:53,  6.93it/s]2024-05-26 21:35:14,077 - train - INFO - Train step 154, Loss: 38.601348876953125\n",
      "  0%|                         | 156/200000 [01:24<8:01:45,  6.91it/s]2024-05-26 21:35:14,223 - train - INFO - Train step 155, Loss: 38.159934997558594\n",
      "  0%|                         | 157/200000 [01:24<8:01:28,  6.92it/s]2024-05-26 21:35:14,367 - train - INFO - Train step 156, Loss: 38.046566009521484\n",
      "  0%|                         | 158/200000 [01:24<8:01:40,  6.91it/s]2024-05-26 21:35:14,512 - train - INFO - Train step 157, Loss: 38.9193115234375\n",
      "  0%|                         | 159/200000 [01:24<8:01:22,  6.92it/s]2024-05-26 21:35:14,656 - train - INFO - Train step 158, Loss: 39.17191696166992\n",
      "  0%|                         | 160/200000 [01:24<8:01:28,  6.92it/s]2024-05-26 21:35:14,801 - train - INFO - Train step 159, Loss: 36.92844772338867\n",
      "  0%|                         | 160/200000 [01:24<8:01:32,  6.92it/s]2024-05-26 21:35:14,945 - train - INFO - Train step 160, Loss: 36.95285415649414\n",
      "  0%|                         | 161/200000 [01:24<8:01:36,  6.92it/s]2024-05-26 21:35:15,090 - train - INFO - Train step 161, Loss: 38.11262893676758\n",
      "  0%|                         | 162/200000 [01:25<8:01:40,  6.91it/s]2024-05-26 21:35:15,235 - train - INFO - Train step 162, Loss: 37.19998550415039\n",
      "  0%|                         | 164/200000 [01:25<8:02:27,  6.90it/s]2024-05-26 21:35:15,380 - train - INFO - Train step 163, Loss: 37.79743194580078\n",
      "  0%|                         | 165/200000 [01:25<8:02:17,  6.91it/s]2024-05-26 21:35:15,525 - train - INFO - Train step 164, Loss: 37.36918258666992\n",
      "  0%|                         | 166/200000 [01:25<8:02:29,  6.90it/s]2024-05-26 21:35:15,670 - train - INFO - Train step 165, Loss: 37.667747497558594\n",
      "  0%|                         | 167/200000 [01:25<8:01:49,  6.91it/s]2024-05-26 21:35:15,814 - train - INFO - Train step 166, Loss: 37.78486251831055\n",
      "  0%|                         | 167/200000 [01:25<8:01:47,  6.91it/s]2024-05-26 21:35:15,958 - train - INFO - Train step 167, Loss: 37.17334747314453\n",
      "  0%|                         | 168/200000 [01:25<8:00:56,  6.92it/s]2024-05-26 21:35:16,103 - train - INFO - Train step 168, Loss: 38.301361083984375\n",
      "  0%|                         | 170/200000 [01:26<8:01:53,  6.91it/s]2024-05-26 21:35:16,248 - train - INFO - Train step 169, Loss: 36.79762649536133\n",
      "  0%|                         | 171/200000 [01:26<8:01:51,  6.91it/s]2024-05-26 21:35:16,393 - train - INFO - Train step 170, Loss: 37.924110412597656\n",
      "  0%|                         | 172/200000 [01:26<8:01:47,  6.91it/s]2024-05-26 21:35:16,537 - train - INFO - Train step 171, Loss: 36.838600158691406\n",
      "  0%|                         | 173/200000 [01:26<8:01:39,  6.91it/s]2024-05-26 21:35:16,682 - train - INFO - Train step 172, Loss: 36.362728118896484\n",
      "  0%|                         | 174/200000 [01:26<8:01:42,  6.91it/s]2024-05-26 21:35:16,826 - train - INFO - Train step 173, Loss: 36.794654846191406\n",
      "  0%|                         | 174/200000 [01:26<8:01:46,  6.91it/s]2024-05-26 21:35:16,971 - train - INFO - Train step 174, Loss: 36.68719482421875\n",
      "  0%|                         | 176/200000 [01:27<8:02:26,  6.90it/s]2024-05-26 21:35:17,116 - train - INFO - Train step 175, Loss: 37.24650573730469\n",
      "  0%|                         | 176/200000 [01:27<8:02:29,  6.90it/s]2024-05-26 21:35:17,261 - train - INFO - Train step 176, Loss: 36.183616638183594\n",
      "  0%|                         | 178/200000 [01:27<8:02:31,  6.90it/s]2024-05-26 21:35:17,406 - train - INFO - Train step 177, Loss: 37.08257293701172\n",
      "  0%|                         | 179/200000 [01:27<8:01:37,  6.91it/s]2024-05-26 21:35:17,550 - train - INFO - Train step 178, Loss: 35.467533111572266\n",
      "  0%|                         | 180/200000 [01:27<8:01:19,  6.92it/s]2024-05-26 21:35:17,695 - train - INFO - Train step 179, Loss: 35.78169250488281\n",
      "  0%|                         | 180/200000 [01:27<8:01:25,  6.92it/s]2024-05-26 21:35:17,841 - train - INFO - Train step 180, Loss: 36.37150573730469\n",
      "  0%|                         | 182/200000 [01:27<8:02:27,  6.90it/s]2024-05-26 21:35:17,985 - train - INFO - Train step 181, Loss: 35.121986389160156\n",
      "  0%|                         | 183/200000 [01:28<8:02:07,  6.91it/s]2024-05-26 21:35:18,130 - train - INFO - Train step 182, Loss: 35.551055908203125\n",
      "  0%|                         | 183/200000 [01:28<8:02:11,  6.91it/s]2024-05-26 21:35:18,275 - train - INFO - Train step 183, Loss: 35.36262893676758\n",
      "  0%|                         | 185/200000 [01:28<8:02:05,  6.91it/s]2024-05-26 21:35:18,419 - train - INFO - Train step 184, Loss: 34.75762939453125\n",
      "  0%|                         | 186/200000 [01:28<8:01:51,  6.91it/s]2024-05-26 21:35:18,564 - train - INFO - Train step 185, Loss: 35.4512939453125\n",
      "  0%|                         | 187/200000 [01:28<8:02:06,  6.91it/s]2024-05-26 21:35:18,709 - train - INFO - Train step 186, Loss: 35.293453216552734\n",
      "  0%|                         | 187/200000 [01:28<8:02:05,  6.91it/s]2024-05-26 21:35:18,853 - train - INFO - Train step 187, Loss: 35.635292053222656\n",
      "  0%|                         | 188/200000 [01:28<8:01:58,  6.91it/s]2024-05-26 21:35:18,999 - train - INFO - Train step 188, Loss: 35.09104919433594\n",
      "  0%|                         | 190/200000 [01:29<8:02:17,  6.90it/s]2024-05-26 21:35:19,143 - train - INFO - Train step 189, Loss: 35.13691711425781\n",
      "  0%|                         | 191/200000 [01:29<8:02:16,  6.91it/s]2024-05-26 21:35:19,288 - train - INFO - Train step 190, Loss: 34.685890197753906\n",
      "  0%|                         | 192/200000 [01:29<8:02:22,  6.90it/s]2024-05-26 21:35:19,433 - train - INFO - Train step 191, Loss: 36.14870071411133\n",
      "  0%|                         | 193/200000 [01:29<8:02:18,  6.90it/s]2024-05-26 21:35:19,578 - train - INFO - Train step 192, Loss: 35.10702896118164\n",
      "  0%|                         | 194/200000 [01:29<8:01:51,  6.91it/s]2024-05-26 21:35:19,722 - train - INFO - Train step 193, Loss: 35.83671951293945\n",
      "  0%|                         | 194/200000 [01:29<8:01:54,  6.91it/s]2024-05-26 21:35:19,868 - train - INFO - Train step 194, Loss: 35.562923431396484\n",
      "  0%|                         | 195/200000 [01:29<8:02:52,  6.90it/s]2024-05-26 21:35:20,013 - train - INFO - Train step 195, Loss: 35.509613037109375\n",
      "  0%|                         | 197/200000 [01:30<8:02:16,  6.90it/s]2024-05-26 21:35:20,158 - train - INFO - Train step 196, Loss: 33.85942077636719\n",
      "  0%|                         | 197/200000 [01:30<8:02:26,  6.90it/s]2024-05-26 21:35:20,302 - train - INFO - Train step 197, Loss: 34.85634994506836\n",
      "  0%|                         | 198/200000 [01:30<8:01:45,  6.91it/s]2024-05-26 21:35:20,447 - train - INFO - Train step 198, Loss: 35.40446472167969\n",
      "  0%|                         | 200/200000 [01:30<8:02:12,  6.91it/s]2024-05-26 21:35:20,592 - train - INFO - Train step 199, Loss: 35.45988845825195\n",
      "  0%|                         | 200/200000 [01:30<8:02:17,  6.90it/s]2024-05-26 21:35:20,736 - train - INFO - Train step 200, Loss: 34.2253532409668\n",
      "  0%|                         | 202/200000 [01:30<8:02:03,  6.91it/s]2024-05-26 21:35:20,881 - train - INFO - Train step 201, Loss: 34.21379470825195\n",
      "  0%|                         | 203/200000 [01:30<8:03:19,  6.89it/s]2024-05-26 21:35:21,027 - train - INFO - Train step 202, Loss: 33.813602447509766\n",
      "  0%|                         | 203/200000 [01:30<8:03:23,  6.89it/s]2024-05-26 21:35:21,172 - train - INFO - Train step 203, Loss: 33.625587463378906\n",
      "  0%|                         | 204/200000 [01:31<8:02:41,  6.90it/s]2024-05-26 21:35:21,316 - train - INFO - Train step 204, Loss: 34.44392776489258\n",
      "  0%|                         | 206/200000 [01:31<8:02:37,  6.90it/s]2024-05-26 21:35:21,462 - train - INFO - Train step 205, Loss: 33.559234619140625\n",
      "  0%|                         | 207/200000 [01:31<8:02:21,  6.90it/s]2024-05-26 21:35:21,606 - train - INFO - Train step 206, Loss: 34.6308708190918\n",
      "  0%|                         | 208/200000 [01:31<8:02:32,  6.90it/s]2024-05-26 21:35:21,751 - train - INFO - Train step 207, Loss: 34.85163116455078\n",
      "  0%|                         | 208/200000 [01:31<8:02:34,  6.90it/s]2024-05-26 21:35:21,897 - train - INFO - Train step 208, Loss: 34.42818069458008\n",
      "  0%|                         | 209/200000 [01:31<8:03:31,  6.89it/s]2024-05-26 21:35:22,042 - train - INFO - Train step 209, Loss: 33.643470764160156\n",
      "  0%|                         | 210/200000 [01:31<8:02:54,  6.90it/s]2024-05-26 21:35:22,186 - train - INFO - Train step 210, Loss: 33.77755355834961\n",
      "  0%|                         | 211/200000 [01:32<8:02:23,  6.90it/s]2024-05-26 21:35:22,331 - train - INFO - Train step 211, Loss: 33.7251091003418\n",
      "  0%|                         | 213/200000 [01:32<8:02:00,  6.91it/s]2024-05-26 21:35:22,476 - train - INFO - Train step 212, Loss: 34.25078582763672\n",
      "  0%|                         | 214/200000 [01:32<8:02:07,  6.91it/s]2024-05-26 21:35:22,621 - train - INFO - Train step 213, Loss: 33.851585388183594\n",
      "  0%|                         | 215/200000 [01:32<8:01:57,  6.91it/s]2024-05-26 21:35:22,765 - train - INFO - Train step 214, Loss: 33.58810806274414\n",
      "  0%|                         | 215/200000 [01:32<8:01:57,  6.91it/s]2024-05-26 21:35:22,910 - train - INFO - Train step 215, Loss: 33.15162658691406\n",
      "  0%|                         | 216/200000 [01:32<8:01:49,  6.91it/s]2024-05-26 21:35:23,055 - train - INFO - Train step 216, Loss: 33.873870849609375\n",
      "  0%|                         | 218/200000 [01:33<8:01:58,  6.91it/s]2024-05-26 21:35:23,199 - train - INFO - Train step 217, Loss: 33.04988479614258\n",
      "  0%|                         | 219/200000 [01:33<8:02:04,  6.91it/s]2024-05-26 21:35:23,344 - train - INFO - Train step 218, Loss: 32.58475875854492\n",
      "  0%|                         | 220/200000 [01:33<8:02:11,  6.91it/s]2024-05-26 21:35:23,489 - train - INFO - Train step 219, Loss: 32.150699615478516\n",
      "  0%|                         | 221/200000 [01:33<8:02:31,  6.90it/s]2024-05-26 21:35:23,634 - train - INFO - Train step 220, Loss: 32.77277755737305\n",
      "  0%|                         | 222/200000 [01:33<8:01:48,  6.91it/s]2024-05-26 21:35:23,779 - train - INFO - Train step 221, Loss: 33.36869430541992\n",
      "  0%|                         | 223/200000 [01:33<8:01:40,  6.91it/s]2024-05-26 21:35:23,923 - train - INFO - Train step 222, Loss: 32.58665084838867\n",
      "  0%|                         | 223/200000 [01:33<8:01:48,  6.91it/s]2024-05-26 21:35:24,068 - train - INFO - Train step 223, Loss: 32.85789489746094\n",
      "  0%|                         | 225/200000 [01:34<8:01:51,  6.91it/s]2024-05-26 21:35:24,213 - train - INFO - Train step 224, Loss: 32.09490966796875\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "torchrun --standalone --nproc_per_node=8 -m cs336_basics.scripts.train \\\n",
    "--train-path ../scratch/paloma_c4_100_domains_val_tokenized.bin \\\n",
    "--dev-path ../scratch/paloma_c4_100_domains_val_tokenized.bin \\\n",
    "--output-dir out/train_on_val \\\n",
    "--vocab-size 50257 \\\n",
    "--context-length 512 \\\n",
    "--d-model 768 \\\n",
    "--num-layers 12 \\\n",
    "--num-heads 12 \\\n",
    "--d-ff 3072 \\\n",
    "--attn-pdrop 0.1 \\\n",
    "--residual-pdrop 0.1 \\\n",
    "--batch-size 32 \\\n",
    "--train-steps 200000 \\\n",
    "--eval-iters 1000 \\\n",
    "--eval-interval 2000 \\\n",
    "--learning-rate 1e-3 \\\n",
    "--lr-scheduler cosine \\\n",
    "--weight-decay 0.1 \\\n",
    "--warmup-ratio 0.01 \\\n",
    "--grad-clip 1.0 \\\n",
    "--dtype bfloat16 \\\n",
    "--wandb-project cs336-a4 \\\n",
    "--compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfaffd6-9dcd-4e4b-83e3-c86ad51d31a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
